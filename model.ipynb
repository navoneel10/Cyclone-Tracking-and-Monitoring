import numpy as np
import torch 
from torch.utils.data import Dataset, DataLoader
import glob
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix, accuracy_score
import cv2
import random
import pandas as pd
import sys
cyclone = []
normal = []

for f in glob.iglob('C:/Users/ghosh/Downloads/Cyclone/yes/*.jpg'):
    img = cv2.imread(f)
    img = cv2.resize(img,(128,128))
    b, g, r = cv2.split(img)
    cv2.merge([r , g , b])
    cyclone.append(img)
for f in glob.iglob('C:/Users/ghosh/Downloads/Cyclone/no/*.jpg'):
    img = cv2.imread(f)
    img = cv2.resize(img,(128,128))
    b, g, r = cv2.split(img)
    cv2.merge([r , g , b])
    normal.append(img)

normal = np.array(normal,dtype = np.float32)
cyclone = np.array(cyclone,dtype = np.float32)
#dtype = np.float32
All = np.concatenate((normal,cyclone))
All.shape
def plot_random(normal, cyclone, num = 5):
    normal_images = normal[np.random.choice(normal.shape[0],num,replace = False)]
    cyclone_images = cyclone[np.random.choice(cyclone.shape[0],num,replace = False)]

    plt.figure(figsize=(16,9))
    for i in range(num):
        plt.subplot(1,num,i+1)
        plt.title("normal")
        plt.imshow(normal_images[i])
    plt.figure(figsize=(16,9))
    for i in range(num):
        plt.subplot(1,num,i+1)
        plt.title("cyclone")
        plt.imshow((cyclone_images[i] * 255).astype(np.uint8))
plot_random(normal,cyclone)
class Dataset(object):
    def __getitem__(self, index):
        raise NotImplementedError
    def __len__(self):
        raise NotImplementedError
    def __add__(self, other):
        return ConcatDataset([self, other])
class MRI(Dataset):
    def __init__(self):
        cyclone = []
        normal = []
        
        for f in glob.iglob('C:/Users/ghosh/Downloads/Cyclone/yes/*.jpg'):
            img = cv2.imread(f)
            img = cv2.resize(img,(128,128))
            b, g, r = cv2.split(img)
            img = cv2.merge([r , g , b])
            img = img.reshape((img.shape[2],img.shape[1],img.shape[0]))
            cyclone.append(img)
        for f in glob.iglob('C:/Users/ghosh/Downloads/Cyclone/no/*.jpg'):
            img = cv2.imread(f)
            img = cv2.resize(img,(128,128))
            b, g, r = cv2.split(img)
            img = cv2.merge([r , g , b])
            img = img.reshape((img.shape[2],img.shape[1],img.shape[0]))
            normal.append(img)

        #our images
        normal = np.array(normal,dtype = np.float32)
        cyclone = np.array(cyclone,dtype = np.float32)
        
        #our labels
        cyclone_label = np.ones(cyclone.shape[0],dtype = np.float32)
        normal_label = np.zeros(normal.shape[0],dtype = np.float32)
        #concatenate              
        self.images = np.concatenate((cyclone, normal),axis = 0)
        self.labels = np.concatenate((cyclone_label,normal_label),axis = 0)
    def __len__(self):
        return self.images.shape[0]
    def __getitem__(self, index):
        sample = {"images": self.images[index] , "labels":self.labels[index]}
        return sample
    def normalize(self):
        self.images = self.images/255.0
mri = MRI()
mri.normalize() 
index = list(range(len(mri)))
random.shuffle(index)
for idx in index:
    sample = mri[idx]
    img = sample['images']
    img = img.reshape(img.shape[1],img.shape[2],img.shape[0])
    plt.imshow(img)
    plt.show()
    
it = iter(mri)
for i in range(10):
    sample = next(it)
    img = sample['images']
    label = sample['labels']
    plt.imshow(img.reshape(img.shape[1],img.shape[2],img.shape[0]))
    print(label)
    plt.show()
dataloader = DataLoader(mri, batch_size = 10, shuffle = True)
for sample in dataloader:
    img = sample['images']
    # img = img.reshape(img.shape[1],img.shape[2],img.shape[0])
    # plt.imshow(img)
    # plt.show()
import torch.nn as nn
import torch.nn.functional as F

class CNN(nn.Module):
    def __init__(self):
        super(CNN,self).__init__()
        self.cnn_model = nn.Sequential(
        #first convolution layer responsible for detecting 
        nn.Conv2d(in_channels = 3, out_channels = 6, kernel_size = 5),
        nn.Tanh(),
        nn.AvgPool2d(kernel_size = 2, stride = 5),
        #first layer output second layer input
        nn.Conv2d(in_channels = 6, out_channels = 16, kernel_size = 5),
        nn.Tanh(),
        nn.AvgPool2d(kernel_size = 2, stride = 5))
        
        self.fc_model = nn.Sequential(
        nn.Linear(in_features = 256, out_features = 120),
        nn.Tanh(),
        nn.Linear(in_features = 120, out_features = 84),
        nn.Tanh(),
        nn.Linear(in_features = 84, out_features = 1))
    def forward(self, x):
        x = self.cnn_model(x)
        #flattens the 2d array
        x = x.view(x.size(0), -1)
        x = self.fc_model(x)
        x = F.sigmoid(x)

        return x
        
model = CNN()
model
model.cnn_model
model.cnn_model[0].weight.shape
model.cnn_model[0].weight[0].shape
model.cnn_model[0].weight[1][1]
model.fc_model
model.fc_model[0]
model.fc_model[0].weight.shape
mri_dataset = MRI()
mri_dataset.normalize()
device = torch.device('cuda:0')
model = CNN().to(device)
dataloader = DataLoader(mri_dataset,batch_size = 32,shuffle = False)
model.eval()
outputs = []
y_true = []

with torch.no_grad():
    
    for d in dataloader:
        image = d['images'].to(device)
        label = d['labels'].to(device)
    
        y_hat = model(image)
        outputs.append(y_hat.cpu().detach().numpy())
        y_true.append(label.cpu().detach().numpy())
    
outputs = np.concatenate(outputs,axis = 0).squeeze()
y_true = np.concatenate(y_true,axis = 0).squeeze()
def threshold(scores,threshold = 0.50,minimum = 0,maximum = 1.0):
    x = np.array(list(scores))
    x[x >= threshold] = maximum
    x[x < threshold] = minimum
    return x
accuracy_score(y_true,threshold(outputs))
import seaborn as sns

plt.figure(figsize = (16,9))
cm = confusion_matrix(y_true,threshold(outputs))
ax = plt.subplot()
sns.heatmap(cm,annot = True,fmt = 'g',ax = ax, annot_kws = {"size" :20})

#labels,titles and ticks
ax.set_xlabel('Predicted',fontsize = 20)
ax.set_ylabel('True label',fontsize = 20)
ax.set_title('Confusion matrix',fontsize = 20)
ax.xaxis.set_ticklabels(['Normal','Cyclone'],fontsize = 20)
ax.yaxis.set_ticklabels(['Cyclone','Normal'],fontsize = 20)
plt.figure(figsize = (16,9))
plt.plot(outputs)
plt.axvline(x=len(cyclone),color='r',linestyle='--')
plt.grid()
eta = 0.0001
EPOCH = 600
optimizer = torch.optim.Adam(model.parameters(),lr = eta)
dataloader = DataLoader(mri_dataset, batch_size = 32, shuffle = False)
model.train()
for epoch in range(1, EPOCH):
    losses =[]
    for d in dataloader:
        optimizer.zero_grad()
        data = d['images'].to(device)
        label = d['labels'].to(device)
        y_hat = model(data)
        # define loss function
        error = nn.BCELoss()
        loss = torch.sum(error(y_hat.squeeze(),label))
        loss.backward() #computes back propagation
        optimizer.step()
        losses.append(loss.item())
    if (epoch+1) % 10 == 0:
        print('Train Epoch: {}\tLoss: {:.6f}'.format(epoch+1, np.mean(losses)))
model.eval()
outputs = []
y_true = []

with torch.no_grad():
    
    for d in dataloader:
        image = d['images'].to(device)
        label = d['labels'].to(device)
    
        y_hat = model(image)
        outputs.append(y_hat.cpu().detach().numpy())
        y_true.append(label.cpu().detach().numpy())
    
outputs = np.concatenate(outputs,axis = 0).squeeze()

y_true = np.concatenate(y_true,axis = 0).squeeze()
accuracy_score(y_true,threshold(outputs))
import seaborn as sns

plt.figure(figsize = (16,9))
cm = confusion_matrix(y_true,threshold(outputs))
ax = plt.subplot()
sns.heatmap(cm,annot = True,fmt = 'g',ax = ax, annot_kws = {"size" :20})

#labels,titles and ticks
ax.set_xlabel('Predicted',fontsize = 20)
ax.set_ylabel('True label',fontsize = 20)
ax.set_title('Confusion matrix',fontsize = 20)
ax.xaxis.set_ticklabels(['Normal','Cyclone'],fontsize = 20)
ax.yaxis.set_ticklabels(['Cyclone','Normal'],fontsize = 20)
plt.figure(figsize = (16,9))
plt.plot(outputs)
plt.axvline(x=len(cyclone),color='r',linestyle='--')
plt.grid()
for i in outputs:
    
